{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb143da-0338-4c39-ba99-5d2b6543c6d0",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd749482-dc41-4cd3-a7b8-853451d5e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c115790-0fd5-4b48-b336-c13a5f11ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare Sample Data\n",
    "data = {\n",
    "    'Size': ['Small', 'Medium', 'Large', 'Medium', 'Extra Large', 'Small'],\n",
    "    'Price': [10, 20, 30, 25, 40, 15]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ade9cc4-1804-474b-a178-fddf341bbf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "          Size  Price\n",
      "0        Small     10\n",
      "1       Medium     20\n",
      "2        Large     30\n",
      "3       Medium     25\n",
      "4  Extra Large     40\n",
      "5        Small     15\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da2a1c8-2141-4962-b032-de2636c9cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize the LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3686c8f-2145-42e8-b26a-01c832e2d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fit and Transform the Categorical Column\n",
    "# The 'fit' step learns the unique labels (Small, Medium, Large, etc.)\n",
    "# The 'transform' step converts them to integers (0, 1, 2, etc.)\n",
    "df['Size_Encoded'] = le.fit_transform(df['Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f139a9b5-8049-4101-8274-12dd79dbce42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after Label Encoding:\n",
      "          Size  Price  Size_Encoded\n",
      "0        Small     10             3\n",
      "1       Medium     20             2\n",
      "2        Large     30             1\n",
      "3       Medium     25             2\n",
      "4  Extra Large     40             0\n",
      "5        Small     15             3\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 4. Display the Result\n",
    "print(\"Data after Label Encoding:\")\n",
    "print(df)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1fc2a2-f2ca-4548-82de-5f85121812d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Classes (Original Labels):\n",
      "['Extra Large' 'Large' 'Medium' 'Small']\n"
     ]
    }
   ],
   "source": [
    "# 5. Accessing the learned classes (optional)\n",
    "print(\"Learned Classes (Original Labels):\")\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05d0249-4c58-4275-9e93-e16000ef4a76",
   "metadata": {},
   "source": [
    "## Inverse Transform"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95e0fedd-a233-45ac-88a7-d5f0fb560de5",
   "metadata": {},
   "source": [
    "You can also convert the encoded numerical values back to their original categorical labels using the inverse_transform method to display result in original form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f95a422-6d28-4286-912d-277abbda08c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Labels recovered from Encoded Values:\n",
      "['Small' 'Medium' 'Large' 'Medium' 'Extra Large' 'Small']\n"
     ]
    }
   ],
   "source": [
    "# Use the fitted encoder 'le' from the previous step\n",
    "encoded_values = df['Size_Encoded']\n",
    "\n",
    "original_labels = le.inverse_transform(encoded_values)\n",
    "\n",
    "print(\"Original Labels recovered from Encoded Values:\")\n",
    "print(original_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1726cd69-3b0c-4ddf-a215-59cdd45e19d6",
   "metadata": {},
   "source": [
    "One Hot Encoding (OHE) implementation in Python is typically done using one of two primary tools: pandas' get_dummies() function or scikit-learn's OneHotEncoder class.\n",
    "\n",
    "While get_dummies() is simple for quick data preparation, scikit-learn's OneHotEncoder is preferred within a machine learning pipeline (like a ColumnTransformer) because it learns the categories during the fit phase and applies the transformation consistently, which is crucial for handling training and test sets separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ad9e1-393a-42c3-b4f7-76756a034fc8",
   "metadata": {},
   "source": [
    "# Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d7bfe9-11f3-4d41-bc9b-e3397ee73c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "  Education_Level  Salary\n",
      "0     High School   40000\n",
      "1        Master's  100000\n",
      "2      Bachelor's   60000\n",
      "3             PhD  150000\n",
      "4     High School   35000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# 1. Prepare Sample Data\n",
    "data = {\n",
    "    'Education_Level': ['High School', 'Master\\'s', 'Bachelor\\'s', 'PhD', 'High School'],\n",
    "    'Salary': [40000, 100000, 60000, 150000, 35000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f1398ae-0c80-496d-817d-eec14c5435f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define the Intrinsic Order\n",
    "# The order is defined from lowest rank to highest rank (0 to N-1).\n",
    "# We must include ALL unique categories present in the data.\n",
    "education_categories = ['High School', 'Bachelor\\'s', 'Master\\'s', 'PhD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0807ea57-47ca-4b28-a2ae-dd1443c3aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Initialize the OrdinalEncoder\n",
    "# The 'categories' parameter takes a list of lists.\n",
    "# Since we are only encoding one column, we pass [education_categories].\n",
    "encoder = OrdinalEncoder(categories=[education_categories])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18716aa3-9c62-4430-946c-2a652171e40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after Ordinal Encoding (Correct Order Maintained):\n",
      "  Education_Level  Salary  Education_Encoded\n",
      "0     High School   40000                0.0\n",
      "1        Master's  100000                2.0\n",
      "2      Bachelor's   60000                1.0\n",
      "3             PhD  150000                3.0\n",
      "4     High School   35000                0.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 4. Fit and Transform the Data\n",
    "# The encoder learns the mapping: High School=0, Bachelor's=1, Master's=2, PhD=3\n",
    "df['Education_Encoded'] = encoder.fit_transform(df[['Education_Level']])\n",
    "\n",
    "print(\"Data after Ordinal Encoding (Correct Order Maintained):\")\n",
    "print(df)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3401633-c09d-40b9-b85e-3abff6060651",
   "metadata": {},
   "source": [
    "# OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3790da-74b1-4422-b80b-0207d84250d3",
   "metadata": {},
   "source": [
    "## Using pandas.get_dummies() (Simple and Fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8512d658-f006-4671-890c-a3ce9af7c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare Sample Data\n",
    "data = {\n",
    "    'City': ['New York', 'London', 'Paris', 'London', 'New York'],\n",
    "    'Gender': ['Male', 'Female', 'Female', 'Male', 'Female'],\n",
    "    'Age': [30, 25, 40, 35, 22]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1eef2dc-5145-47e8-9e31-b1bcdf59aef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "       City  Gender  Age\n",
      "0  New York    Male   30\n",
      "1    London  Female   25\n",
      "2     Paris  Female   40\n",
      "3    London    Male   35\n",
      "4  New York  Female   22\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88e008b8-7287-4618-96e5-bc86aef32461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Apply One Hot Encoding\n",
    "# The 'columns' argument specifies which columns to encode.\n",
    "# The 'drop_first=True' argument is optional but highly recommended to avoid multicollinearity.\n",
    "df_encoded = pd.get_dummies(df, columns=['City', 'Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c4bd2cc-8f8f-4cbc-b9e6-86d4b38b42b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after One Hot Encoding (using pandas.get_dummies):\n",
      "   Age  City_New York  City_Paris  Gender_Male\n",
      "0   30           True       False         True\n",
      "1   25          False       False        False\n",
      "2   40          False        True        False\n",
      "3   35          False       False         True\n",
      "4   22           True       False        False\n"
     ]
    }
   ],
   "source": [
    "print(\"Data after One Hot Encoding (using pandas.get_dummies):\")\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f51c63f-b09d-4daa-b7b5-371ea62cb78e",
   "metadata": {},
   "source": [
    "##  Using sklearn.preprocessing.OneHotEncoder (Best for Pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbbe6c66-88d2-4811-b8c4-ef6d1ea99f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Sample Data\n",
    "data = pd.DataFrame({\n",
    "    'City': ['New York', 'London', 'Paris', 'London', 'New York'],\n",
    "    'Gender': ['Male', 'Female', 'Female', 'Male', 'Female'],\n",
    "    'Age': [30, 25, 40, 35, 22]\n",
    "})\n",
    "\n",
    "# Identify categorical features to encode\n",
    "categorical_features = ['City', 'Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e131d1e-db18-49ad-a9db-5d99a6a1f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize the Encoder\n",
    "# drop='first' is used to avoid multicollinearity.\n",
    "# sparse_output=False ensures a dense NumPy array is returned.\n",
    "ohe = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12048258-fd79-44ba-af5e-d710de2e3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Fit and Transform the Categorical Data\n",
    "# We fit only on the categorical columns\n",
    "encoded_array = ohe.fit_transform(data[categorical_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19a01361-6940-454b-8830-389cb8ab777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Get the new feature names\n",
    "# Use get_feature_names_out to create column names like 'City_London', 'Gender_Male'\n",
    "feature_names = ohe.get_feature_names_out(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33cdc885-2640-4e24-bc8a-d1d3c2da00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create a DataFrame from the encoded array\n",
    "df_encoded_cats = pd.DataFrame(encoded_array, columns=feature_names, index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8266a63e-8281-4f60-9b8b-bfc86ff66c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame after OHE:\n",
      "   Age  City_New York  City_Paris  Gender_Male\n",
      "0   30            1.0         0.0          1.0\n",
      "1   25            0.0         0.0          0.0\n",
      "2   40            0.0         1.0          0.0\n",
      "3   35            0.0         0.0          1.0\n",
      "4   22            1.0         0.0          0.0\n"
     ]
    }
   ],
   "source": [
    "# 5. Concatenate with the original numerical data\n",
    "# Drop the original categorical columns before concatenating\n",
    "df_final = pd.concat([data.drop(columns=categorical_features), df_encoded_cats], axis=1)\n",
    "\n",
    "print(\"Final DataFrame after OHE:\")\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c937f-3240-463a-80c6-6c3e001f8d96",
   "metadata": {},
   "source": [
    "# Target Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86e72212-c812-4581-b175-49a9b7bfe8f0",
   "metadata": {},
   "source": [
    "Since Target Encoding is not part of the core scikit-learn library, we use the excellent third-party library, category_encoders.\n",
    "We'll use the TargetEncoder class from the category_encoders library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "070300a7-02ec-431a-8a91-da93da07bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install category-encoders --run this "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e4df8-a3bf-4629-a15f-66e72a5206e1",
   "metadata": {},
   "source": [
    "## Simple Implementation (Without Cross-Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc9546ec-e260-4d30-8f0a-dcc68498f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# 1. Prepare Sample Data\n",
    "# 'City' is the high-cardinality categorical feature.\n",
    "# 'Default' is the binary target variable (0 or 1).\n",
    "data = {\n",
    "    'City': ['London', 'Paris', 'New York', 'London', 'Berlin', 'Paris', 'London', 'Berlin'],\n",
    "    'Annual_Income': [50000, 60000, 70000, 45000, 80000, 55000, 65000, 75000],\n",
    "    'Default': [0, 1, 0, 0, 1, 1, 0, 1]  # Target variable (e.g., loan default)\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc013961-2501-4544-a4fb-c6abb31d02bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "       City  Annual_Income  Default\n",
      "0    London          50000        0\n",
      "1     Paris          60000        1\n",
      "2  New York          70000        0\n",
      "3    London          45000        0\n",
      "4    Berlin          80000        1\n",
      "5     Paris          55000        1\n",
      "6    London          65000        0\n",
      "7    Berlin          75000        1\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = df[['City', 'Annual_Income']]\n",
    "y = df['Default']\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20d0564b-906a-447a-b8d8-211186608a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize the TargetEncoder\n",
    "# 'smoothing' adds a regularization term to mitigate overfitting.\n",
    "# The default smoothing parameter is often a good starting point.\n",
    "encoder = TargetEncoder(cols=['City'], smoothing=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f2fbf52-a832-4df7-9717-f0f1f9219516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after Target Encoding:\n",
      "   City  Annual_Income\n",
      "0   0.5          50000\n",
      "1   0.5          60000\n",
      "2   0.5          70000\n",
      "3   0.5          45000\n",
      "4   0.5          80000\n",
      "5   0.5          55000\n",
      "6   0.5          65000\n",
      "7   0.5          75000\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 3. Fit and Transform the Data\n",
    "# The encoder learns the mean of 'Default' for each 'City'.\n",
    "X_encoded = encoder.fit_transform(X, y)\n",
    "\n",
    "print(\"Data after Target Encoding:\")\n",
    "print(X_encoded)\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70cb02f1-63b0-469b-a2b8-ca9d4ecd54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Understanding the Encoding (Mean Values)\n",
    "# Calculate the mean of 'Default' for each 'City' manually to confirm:\n",
    "# London: (0+0+0)/3 = 0.0\n",
    "# Paris: (1+1)/2 = 1.0\n",
    "# New York: 0/1 = 0.0\n",
    "# Berlin: (1+1)/2 = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1f8fd4c-f388-412a-a8ad-d588d8d14cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Target Means (Approximated due to Smoothing):\n",
      "London: 0.5000\n",
      "Paris: 0.5000\n",
      "New York: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# The encoded values (e.g., for City) will be slightly different from the exact mean\n",
    "# due to the 'smoothing' parameter, which pulls the mean slightly towards the global mean.\n",
    "print(\"Learned Target Means (Approximated due to Smoothing):\")\n",
    "for category, encoded_value in zip(df['City'].unique(), X_encoded['City'].unique()):\n",
    "    print(f\"{category}: {encoded_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c96aa7-8d82-44f1-8407-9433d170c4cc",
   "metadata": {},
   "source": [
    "## Implementation within Cross-Validation (Best Practice)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e45b436-86d7-43b6-899f-a8027ab7552c",
   "metadata": {},
   "source": [
    "For machine learning, it's crucial to apply Target Encoding only using data from the training folds to avoid target leakage. This is done by incorporating the encoder into a Pipeline used within a cross-validation framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89e11346-5eeb-485a-b687-34c0d5bcbd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 2. Define the Pipeline\n",
    "# Step 1: Target Encode the 'City' column\n",
    "# Step 2: Train a Logistic Regression model\n",
    "pipeline = Pipeline([\n",
    "    ('encoder', TargetEncoder(cols=['City'], smoothing=2.0)),\n",
    "    ('model', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a597d873-d04d-4f43-bddf-14c0da71bfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.6667\n",
      "Fold 2 Accuracy: 0.6667\n",
      "Fold 3 Accuracy: 0.5000\n",
      "------------------------------------------------------------\n",
      "Average Cross-Validation Accuracy: 0.6111\n"
     ]
    }
   ],
   "source": [
    "# 3. Use Cross-Validation to evaluate performance safely\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(cv.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Crucial Step: The encoder is fitted ONLY on the training data (X_train, y_train)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # The transformation is applied to the test data using the means learned from the training data\n",
    "    score = pipeline.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "\n",
    "    print(f\"Fold {fold+1} Accuracy: {score:.4f}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"Average Cross-Validation Accuracy: {np.mean(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e56afe1a-c669-4ca3-96f1-c4f4a958e858",
   "metadata": {},
   "source": [
    "In this cross-validation approach:\n",
    "\n",
    "For each fold, the TargetEncoder calculates the means of the target (y) based only on the training data.\n",
    "\n",
    "It then uses those calculated means to encode both the training set (for model fitting) and the holdout test set (for evaluation).\n",
    "\n",
    "This process prevents target leakage because the test set's target values never influence its own features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b9e43e-fe80-4ffd-8fb8-db7985efe66a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
